{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnames = ['movie_id', 'title', 'genre']\n",
    "movies_df = pd.read_table('ml-1m/movies.dat', names = mnames, sep = \"::\", engine = 'python', encoding='ISO-8859-1')\n",
    "# Loading the cleaned datasets\n",
    "rnames = ['user_id','movie_id','rating','timestamp']\n",
    "ratings_df = pd.read_table(\"ml-1m/ratings.dat\", header =None, sep='::',names=rnames, engine= 'python')\n",
    "uname = ['user_id','gender','age','occupation','zip']\n",
    "users_df = pd.read_table(\"ml-1m/users.dat\", sep='::', header = None, names=uname, engine='python')\n",
    "ratings_df.drop(columns=['timestamp'], inplace=True, axis=1)  # Remove useless features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting the ratings dataset into the feature set (X) and target labels (y)\n",
    "X = ratings_df.drop(columns='rating')\n",
    "y = ratings_df[\"rating\"].values  # The movie ratings are the target variables we want to predict\n",
    "\n",
    "# Preparing train, validation and test datasets.\n",
    "# I have chosen a split ratio of 80%, 10%, 10%, because I want a somewhat large training set at the cost of a\n",
    "# smaller validation and test set. I do not think that a smaller validation (or test) dataset will negatively\n",
    "# impact the generalization ability of the chosen models, because I am only using rather simple ML models\n",
    "# with few hyperparamaters.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# Creating a complete training dataset with X_train and y_train\n",
    "train_df = X_train.copy()\n",
    "train_df[\"rating\"] = y_train\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df[\"rating\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(train_df)\n",
    "training_set = training_set.astype(\"int\")\n",
    "test_set = np.array(train_df)\n",
    "test_set = test_set.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1035,  594,  938,  914, 1836, 1029,  595,  260,  919, 1961, 1207,\n",
       "        745, 2028, 1270, 1962, 3186,  720, 2692, 1197, 2804, 2321, 2762,\n",
       "        661, 2797,  150, 3105, 2791, 1193, 1907, 2918, 1287, 1022,  783,\n",
       "       1246, 1545, 2355,  608,  531, 2018, 1566, 1721,  588, 3114])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[:,1][training_set[:,0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3952\n"
     ]
    }
   ],
   "source": [
    "#take max users id in train and test data\n",
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies =  int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
    "print(nb_users, nb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        ##id of movies that is rated by current users\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        \n",
    "        ##rate of movies that is given by current user\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        \n",
    "        #inialize ratings for all movies\n",
    "        #set 0 for movies that are not rated by current users\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        #movie id starts from 1, 1st movie will be 1st element in rating with index as 0\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(convert(training_set))\n",
    "test_set = torch.FloatTensor(convert(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "\n",
    "    def __init__(self, num_visible, num_hidden, k, learning_rate=1e-3, momentum_coefficient=0.5, weight_decay=1e-4, use_cuda=True):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum_coefficient = momentum_coefficient\n",
    "        self.weight_decay = weight_decay\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        self.weights = torch.randn(num_visible, num_hidden) * 0.1\n",
    "        self.visible_bias = torch.ones(num_visible) * 0.5\n",
    "        self.hidden_bias = torch.zeros(num_hidden)\n",
    "\n",
    "        self.weights_momentum = torch.zeros(num_visible, num_hidden)\n",
    "        self.visible_bias_momentum = torch.zeros(num_visible)\n",
    "        self.hidden_bias_momentum = torch.zeros(num_hidden)\n",
    "\n",
    "    def sample_hidden(self, visible_probabilities):\n",
    "        hidden_activations = torch.matmul(visible_probabilities, self.weights) + self.hidden_bias\n",
    "        hidden_probabilities = self._sigmoid(hidden_activations)\n",
    "        return hidden_probabilities\n",
    "\n",
    "    def sample_visible(self, hidden_probabilities):\n",
    "        visible_activations = torch.matmul(hidden_probabilities, self.weights.t()) + self.visible_bias\n",
    "        visible_probabilities = self._sigmoid(visible_activations)\n",
    "        return visible_probabilities\n",
    "\n",
    "    def contrastive_divergence(self, input_data):\n",
    "        # Positive phase\n",
    "        positive_hidden_probabilities = self.sample_hidden(input_data)\n",
    "        positive_hidden_activations = (positive_hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
    "        positive_associations = torch.matmul(input_data.t(), positive_hidden_activations)\n",
    "\n",
    "        # Negative phase\n",
    "        hidden_activations = positive_hidden_activations\n",
    "\n",
    "        for step in range(self.k):\n",
    "            visible_probabilities = self.sample_visible(hidden_activations)\n",
    "            visible_probabilities[input_data == 0] = 0\n",
    "            hidden_probabilities = self.sample_hidden(visible_probabilities)\n",
    "            hidden_activations = (hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
    "\n",
    "        negative_visible_probabilities = visible_probabilities\n",
    "        negative_hidden_probabilities = hidden_probabilities\n",
    "\n",
    "        negative_associations = torch.matmul(negative_visible_probabilities.t(), negative_hidden_probabilities)\n",
    "\n",
    "        # Update parameters\n",
    "        self.weights_momentum *= self.momentum_coefficient\n",
    "        self.weights_momentum += (positive_associations - negative_associations)\n",
    "\n",
    "        self.visible_bias_momentum *= self.momentum_coefficient\n",
    "        self.visible_bias_momentum += torch.sum(input_data - negative_visible_probabilities, dim=0)\n",
    "\n",
    "        self.hidden_bias_momentum *= self.momentum_coefficient\n",
    "        self.hidden_bias_momentum += torch.sum(positive_hidden_probabilities - negative_hidden_probabilities, dim=0)\n",
    "\n",
    "        batch_size = input_data.size(0)\n",
    "        self.weights += self.weights_momentum * self.learning_rate / batch_size\n",
    "        self.visible_bias += self.visible_bias_momentum * self.learning_rate / batch_size\n",
    "        self.hidden_bias += self.hidden_bias_momentum * self.learning_rate / batch_size\n",
    "\n",
    "        self.weights -= self.weights * self.weight_decay  # L2 weight decay\n",
    "\n",
    "        # Compute reconstruction error\n",
    "        target = torch.flatten(input_data)[torch.flatten(input_data) > 0]\n",
    "        predict = torch.flatten(negative_visible_probabilities)[torch.flatten(input_data) > 0]\n",
    "        error = torch.sum((target - predict) ** 2)\n",
    "        return error\n",
    " \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    def _random_probabilities(self, num):\n",
    "        random_probabilities = torch.rand(num)\n",
    "        return random_probabilities\n",
    "    \n",
    "    def save(self):\n",
    "        torch.save(self.weights, \"./rbm/weights.pt\")\n",
    "        torch.save(self.visible_bias, \"./rbm/visible_bias.pt\")\n",
    "        torch.save(self.hidden_bias, \"./rbm/hidden_bias.pt\")\n",
    "    \n",
    "    def load(self):\n",
    "        self.weights = torch.load(\"./rbm/weights.pt\", map_location=lambda storage, loc: storage)\n",
    "        self.visible_bias = torch.load(\"./rbm/visible_bias.pt\", map_location=lambda storage, loc: storage)\n",
    "        self.hidden_bias = torch.load(\"./rbm/hidden_bias.pt\", map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info> Creating the architecture of the Neural Network\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "print('<Info> Creating the architecture of the Neural Network')\n",
    "# Creating the architecture of the Neural Network\n",
    "nv = len(training_set[0])\n",
    "nh = 125\n",
    "batch_size = 128\n",
    "rbm = RBM(nv, nh, 10, 5e-3)\n",
    "rbm.load()\n",
    "# Training the RBM\n",
    "# nb_epoch = 50\n",
    "# prev_train_loss = 0\n",
    "# s = float(torch.sum(training_set > 0))\n",
    "# for epoch in range(1, nb_epoch + 1):\n",
    "#     train_loss = 0\n",
    "    \n",
    "#     for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "#         batch = training_set[id_user:id_user+batch_size].to(device) / 5.0\n",
    "#         batch_error = rbm.contrastive_divergence(batch)\n",
    "#         train_loss += batch_error\n",
    "#     train_loss = math.sqrt(train_loss / s)\n",
    "#     print('<Info> epoch: '+str(epoch)+' loss: '+str(train_loss))\n",
    "#     if abs(train_loss - prev_train_loss) < 1e-6:\n",
    "#         break\n",
    "#     prev_train_loss = train_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info> Testing the RBM\n",
      "<Info> Test loss: 0.9482224046900545\n",
      "<Info> Completed.\n"
     ]
    }
   ],
   "source": [
    "print('<Info> Testing the RBM')\n",
    "test_loss = 0\n",
    "s = float(torch.sum(test_set > 0))\n",
    "count = 0\n",
    "for id_user in range(nb_users):\n",
    "    # Use the training set to activate neurons  \n",
    "    v = test_set[id_user:id_user+1] / 5.0\n",
    "    h = rbm.sample_hidden(v)\n",
    "    vt = rbm.sample_visible(h)\n",
    "    v = torch.flatten(v)\n",
    "    vt = torch.flatten(vt)[v>0]\n",
    "    v = v[v>0]\n",
    "    test_loss += torch.sum((vt - v) ** 2)\n",
    "test_loss = math.sqrt(test_loss / s)        \n",
    "print('<Info> Test loss: '+ str(test_loss * 5))\n",
    "print('<Info> Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_df = pd.read_csv(\"./films.csv\")\n",
    "nb_genres = len(films_df.columns) - 2\n",
    "films_df = films_df.set_index('movie_id')\n",
    "films_df.drop(columns=[\"title\"], inplace=True)\n",
    "new_index = np.array(range(1, 3953))\n",
    "films_df = films_df.reindex(new_index, fill_value=0)\n",
    "films_matrix = np.array(films_df)\n",
    "films_matrix = films_matrix.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3952, 18) (6040, 3952) 11649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:01<00:00, 3967.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "users_rating_matrix = np.zeros((nb_users, nb_genres))\n",
    "users_prefer_matrix = np.zeros((nb_users, nb_genres))\n",
    "training_array = training_set.numpy()\n",
    "print(films_matrix.shape, training_array.shape, movies_df.size)\n",
    "for i in tqdm(range(nb_users)):\n",
    "    ratings = training_array[i][training_array[i] > 0].reshape(-1, 1)\n",
    "    films = films_matrix[training_array[i] > 0]\n",
    "    films = films * ratings\n",
    "    films_r = np.zeros(films.shape[1]).astype('float64')\n",
    "    films_p = np.sum(films > 0, axis=0) / float(films.shape[0])\n",
    "    for j in range(18):\n",
    "        if np.sum(films[:,j] > 0) > 0:\n",
    "            films_r[j] = np.argmax(np.bincount(films[:,j][films[:,j] > 0].astype('int')))\n",
    "    users_prefer_matrix[i] = films_p\n",
    "    users_rating_matrix[i] = films_r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info> Testing the RBM\n",
      "<Info> Test loss: 10.567309644929423\n",
      "<Info> Completed.\n"
     ]
    }
   ],
   "source": [
    "print('<Info> Testing the RBM')\n",
    "test_loss = 0\n",
    "s = float(torch.sum(test_set > 0))\n",
    "count = 0\n",
    "for id_user in range(nb_users):\n",
    "    # Use the training set to activate neurons  \n",
    "    v = test_set[id_user].numpy()\n",
    "    pred = np.sum(films_matrix[v > 0] * users_prefer_matrix[id_user], axis=1)\n",
    "    v = v[v > 0]\n",
    "    test_loss += np.sum((pred - v) ** 2)\n",
    "test_loss = math.sqrt(test_loss / s)        \n",
    "print('<Info> Test loss: '+ str(test_loss * 5))\n",
    "print('<Info> Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_combine(alpha, beta):\n",
    "    print(alpha, beta)\n",
    "    test_loss = 0\n",
    "    s = float(torch.sum(test_set > 0))\n",
    "    for id_user in range(nb_users):\n",
    "        # Use the training set to activate neurons  \n",
    "        v = test_set[id_user:id_user+1] / 5.0\n",
    "        h = rbm.sample_hidden(v)\n",
    "        vt = rbm.sample_visible(h)\n",
    "\n",
    "        vt = torch.flatten(vt)[torch.flatten(v)>0].numpy() * 5\n",
    "\n",
    "        v = v[0].numpy() * 5\n",
    "        vp = np.sum(films_matrix[v > 0] * users_prefer_matrix[id_user], axis=1)\n",
    "        v = v[v > 0]\n",
    "\n",
    "        pred = alpha * vt + beta * vp \n",
    "\n",
    "        test_loss += np.sum((pred - v) ** 2)\n",
    "    test_loss = math.sqrt(test_loss / s)        \n",
    "    print('Test loss: '+ str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89443 0.11716\n",
      "Test loss: 0.9453826824972438\n"
     ]
    }
   ],
   "source": [
    "test_combine(0.89443, 0.11716)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
